{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rfv *.csv *.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -qU awscli boto3 sagemaker torch torchvision locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import boto3   \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set enviornment vairables for Locust file to pick up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp_suffix = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "endpoint_name = 'triton-tf-' + time_stamp_suffix\n",
    "print(endpoint_name)\n",
    "endpoint_details = {\n",
    "    'endpoint_name': endpoint_name,\n",
    "    'endpoint_type': 'ml.g4dn.4xlarge',\n",
    "    'endpoint_cores': 16,\n",
    "    'endpoint_notes': 'SageMaker-Container'\n",
    "}\n",
    "file_name_string = endpoint_details['endpoint_name'] + '-' + endpoint_details['endpoint_type'] + '-' + endpoint_details['endpoint_notes'] + '-D-' + time_stamp_suffix\n",
    "#https://docs.aws.amazon.com/general/latest/gr/sagemaker.html\n",
    "host_string = 'https://runtime.sagemaker.us-east-2.amazonaws.com/endpoints/' + endpoint_details['endpoint_name'] + '/invocations'\n",
    "\n",
    "test_details  = {\n",
    "    'users': 10, # -u NUM_USERS, --users NUM_USERS Number of concurrent Locust users. Primarily used together with --headless\n",
    "    'spawn_rate': 2, # -r SPAWN_RATE, --spawn-rate SPAWN_RATE The rate per second in which users are spawned. Primarily used together with --headless\n",
    "    'log_level' : 'WARNING', # -L LOGLEVEL Choose between DEBUG/INFO/WARNING/ERROR/CRITICAL. Default is INFO.\n",
    "    'run_time': '10m' # -t RUN_TIME, --run-time RUN_TIME Stop after the specified amount of time, e.g. (300s, 20m, 3h, 1h30m, etc.). Only used together with --headless\n",
    "}\n",
    "print(host_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, time, json\n",
    "from sagemaker import get_execution_role\n",
    "sess    = boto3.Session()\n",
    "sm      = sess.client('sagemaker')\n",
    "region  = sess.region_name\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "print(account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables\n",
    "\n",
    "model_data = 's3://lniniga-mars/ensemble-bert-large.tar.gz' # TAR file containing saved_model.pb file in Triton directory format\n",
    "sm_model_name = 'ensemble-bert-large'\n",
    "#role_name = 'arn:aws:iam::{}:role/service-role/{}'.format(account, 'AmazonSageMaker-ExecutionRole-20210201T205137')\n",
    "role_name = get_execution_role()\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, 'triton-with-tf')\n",
    "print(role_name)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('container/triton/ngnix.conf.template', 'r') as template, open('container/triton/ngnix.conf', 'w') as conf:\n",
    "    conf_str = template.read()\n",
    "    conf.write(conf_str.format(sm_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=triton-with-tf\n",
    "\n",
    "cd container/triton\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName         = sm_model_name,\n",
    "    ExecutionRoleArn  = role_name,\n",
    "    PrimaryContainer  = container)\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "endpoint_config_name = 'triton-tf-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants = [{\n",
    "        'InstanceType'        : endpoint_details['endpoint_type'],\n",
    "        'InitialVariantWeight': 1,\n",
    "        'InitialInstanceCount': 1,\n",
    "        'ModelName'           : sm_model_name,\n",
    "        'VariantName'         : 'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName         = endpoint_name,\n",
    "    EndpointConfigName   = endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {host_string}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run locust. See this link for more options - https://docs.locust.io/en/stable/running-locust-without-web-ui.html. Also, see this blog for more info - https://medium.com/@linh22jan/load-test-with-locust-37c4f85ee2fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cw_start = datetime.datetime.utcnow()\n",
    "%store cw_start\n",
    "!locust -f loadtest/stress-optimized-protobuf.py -u {test_details['users']} -r {test_details['spawn_rate']} -L {test_details['log_level']} -t{test_details['run_time']} --csv={file_name_string} --logfile {file_name_string}.log --headless --host={host_string}\n",
    "cw_end = datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing results from Locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_name_string + '_stats.csv')\n",
    "\n",
    "for index, row in data.head(n=2).iterrows():\n",
    "     print(index, row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model latency from Cloud Watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_stamp_suffix = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "#total_runs = data['Request Count'][0]\n",
    "seconds_conversion = 1000\n",
    "print('Total runs - {}\\n'.format(data['Request Count'][0], time_stamp_suffix))\n",
    "print('Timestamp - {}\\n'.format(time_stamp_suffix))\n",
    "print('Getting Cloudwatch:\\n')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "statistics=['SampleCount', 'Average', 'Minimum', 'Maximum', 'Sum']\n",
    "extended=['p10', 'p50', 'p90', 'p95', 'p100']\n",
    "\n",
    "#ml.c5.9xlarge\t36\n",
    "#ml.c5.4xlarge\t16\n",
    "\n",
    "# Give 5 minute buffer to end\n",
    "#cw_end += datetime.timedelta(minutes=5)\n",
    "\n",
    "# Period must be 1, 5, 10, 30, or multiple of 60\n",
    "# Calculate closest multiple of 60 to the total elapsed time\n",
    "factor = math.ceil((cw_end - cw_start).total_seconds() / 60)\n",
    "period = factor * 60\n",
    "period = int(period)\n",
    "#period = 1\n",
    "\n",
    "print('Time elapsed: {} seconds\\n'.format((cw_end - cw_start).total_seconds()))\n",
    "print('Using period of {} seconds\\n'.format(period))\n",
    "\n",
    "cloudwatch_ready = False\n",
    "# Keep polling CloudWatch metrics until datapoints are available\n",
    "while not cloudwatch_ready:\n",
    "    time.sleep(30)\n",
    "    print('Waiting 30 seconds ...\\n')\n",
    "    # Must use default units of microseconds\n",
    "    model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='ModelLatency',\n",
    "                                             Dimensions=[{'Name': 'EndpointName',\n",
    "                                                          'Value': endpoint_details['endpoint_name']},\n",
    "                                                         {'Name': 'VariantName',\n",
    "                                                          'Value': \"AllTraffic\"}],\n",
    "                                             Namespace=\"AWS/SageMaker\",\n",
    "                                             StartTime=cw_start,\n",
    "                                             EndTime=cw_end,\n",
    "                                             Period=period,\n",
    "                                             Statistics=statistics,\n",
    "                                             ExtendedStatistics=extended\n",
    "                                             )\n",
    "  \n",
    "    if len(model_latency_metrics['Datapoints']) > 0:\n",
    "        print('Model Latency: {} data points'.format(model_latency_metrics['Datapoints'][0]['SampleCount']))\n",
    "        side_avg = model_latency_metrics['Datapoints'][0]['Average'] / seconds_conversion\n",
    "        side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50']  / seconds_conversion\n",
    "        side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90']  / seconds_conversion\n",
    "        side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95']  / seconds_conversion\n",
    "        side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100']  / seconds_conversion\n",
    "        print('Avg | P50 | P90 | P95 | P100')\n",
    "        print('{:.4f} | {:.4f} | {:.4f} | {:.4f}\\n'.format(side_avg, side_p50, side_p90, side_p95, side_p100))\n",
    "        cloudwatch_ready = True\n",
    "    else:\n",
    "        time.sleep(30)\n",
    "        continue\n",
    "\n",
    "\n",
    "    model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='OverheadLatency',\n",
    "                                             Dimensions=[{'Name': 'EndpointName',\n",
    "                                                          'Value': endpoint_details['endpoint_name']},\n",
    "                                                         {'Name': 'VariantName',\n",
    "                                                          'Value': \"AllTraffic\"}],\n",
    "                                             Namespace=\"AWS/SageMaker\",\n",
    "                                             StartTime=cw_start,\n",
    "                                             EndTime=cw_end,\n",
    "                                             Period=period,\n",
    "                                             Statistics=statistics,\n",
    "                                             ExtendedStatistics=extended\n",
    "                                             )\n",
    "  \n",
    "    if len(model_latency_metrics['Datapoints']) > 0:\n",
    "        print('OverheadLatency: {} data points'.format(model_latency_metrics['Datapoints'][0]['SampleCount']))\n",
    "        side_avg = model_latency_metrics['Datapoints'][0]['Average'] / seconds_conversion\n",
    "        side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50']  / seconds_conversion\n",
    "        side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90']  / seconds_conversion\n",
    "        side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95']  / seconds_conversion\n",
    "        side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100']  / seconds_conversion\n",
    "        print('Avg | P50 | P90 | P95 | P100')\n",
    "        print('{:.4f} | {:.4f} | {:.4f} | {:.4f}\\n'.format(side_avg, side_p50, side_p90, side_p95, side_p100))\n",
    "    else:\n",
    "        time.sleep(30)\n",
    "        continue\n",
    "\n",
    "    model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='Invocations',\n",
    "                                     Dimensions=[{'Name': 'EndpointName',\n",
    "                                                  'Value': endpoint_details['endpoint_name']},\n",
    "                                                 {'Name': 'VariantName',\n",
    "                                                  'Value': \"AllTraffic\"}],\n",
    "                                     Namespace=\"AWS/SageMaker\",\n",
    "                                     StartTime=cw_start,\n",
    "                                     EndTime=cw_end,\n",
    "                                     Period=period,\n",
    "                                     Statistics=statistics,\n",
    "                                     ExtendedStatistics=extended\n",
    "                                     )\n",
    "  \n",
    "    if len(model_latency_metrics['Datapoints']) > 0:\n",
    "        print('Invocations: {} \\n'.format(model_latency_metrics['Datapoints'][0]['Sum']))\n",
    "    else:\n",
    "        time.sleep(30)\n",
    "        continue\n",
    "\n",
    "    model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='CPUUtilization',\n",
    "                                     Dimensions=[{'Name': 'EndpointName',\n",
    "                                                  'Value': endpoint_details['endpoint_name']},\n",
    "                                                 {'Name': 'VariantName',\n",
    "                                                  'Value': \"AllTraffic\"}],\n",
    "                                     Namespace=\"/aws/sagemaker/Endpoints\",\n",
    "                                     StartTime=cw_start,\n",
    "                                     EndTime=cw_end,\n",
    "                                     Period=period,\n",
    "                                     Statistics=statistics,\n",
    "                                     ExtendedStatistics=extended\n",
    "                                     )\n",
    "    \n",
    "    if len(model_latency_metrics['Datapoints']) > 0:\n",
    "        print('CPUUtilization: {} data points (adjusted for cores)'.format(model_latency_metrics['Datapoints'][0]['SampleCount']))\n",
    "        side_avg = model_latency_metrics['Datapoints'][0]['Average'] / endpoint_details['endpoint_cores']\n",
    "        side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50'] / endpoint_details['endpoint_cores']\n",
    "        side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90'] / endpoint_details['endpoint_cores']\n",
    "        side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95'] / endpoint_details['endpoint_cores']\n",
    "        side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100'] / endpoint_details['endpoint_cores']\n",
    "        print('Avg | P50 | P90 | P95 | P100')\n",
    "        print('{:.4f} | {:.4f} | {:.4f} | {:.4f}\\n'.format(side_avg, side_p50, side_p90, side_p95, side_p100))\n",
    "    else:\n",
    "        time.sleep(30)\n",
    "        continue\n",
    "        \n",
    "    model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='GPUUtilization',\n",
    "                                     Dimensions=[{'Name': 'EndpointName',\n",
    "                                                  'Value': endpoint_details['endpoint_name']},\n",
    "                                                 {'Name': 'VariantName',\n",
    "                                                  'Value': \"AllTraffic\"}],\n",
    "                                     Namespace=\"/aws/sagemaker/Endpoints\",\n",
    "                                     StartTime=cw_start,\n",
    "                                     EndTime=cw_end,\n",
    "                                     Period=period,\n",
    "                                     Statistics=statistics,\n",
    "                                     ExtendedStatistics=extended\n",
    "                                     )\n",
    "    \n",
    "    if len(model_latency_metrics['Datapoints']) > 0:\n",
    "        print('GPUUtilization: {} data points (adjusted for cores)'.format(model_latency_metrics['Datapoints'][0]['SampleCount']))\n",
    "        side_avg = model_latency_metrics['Datapoints'][0]['Average'] #/ endpoint_details['endpoint_cores']\n",
    "        side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50'] #/ endpoint_details['endpoint_cores']\n",
    "        side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90'] #/ endpoint_details['endpoint_cores']\n",
    "        side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95'] #/ endpoint_details['endpoint_cores']\n",
    "        side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100'] #/ endpoint_details['endpoint_cores']\n",
    "        print('Avg | P50 | P90 | P95 | P100')\n",
    "        print('{:.4f} | {:.4f} | {:.4f} | {:.4f}\\n'.format(side_avg, side_p50, side_p90, side_p95, side_p100))\n",
    "    else:\n",
    "        time.sleep(30)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
